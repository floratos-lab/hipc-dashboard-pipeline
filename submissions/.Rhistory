file = logfile_path(logdir, base_filename, "response_component_duplicates_count.csv"),
row.names = FALSE, col.names = FALSE, quote = FALSE)
# Write out list of duplicated response components by signature
# Have to write in loop because varying number of elements per row
outfile = logfile_path(logdir, base_filename, "response_component_duplicates.txt")
if(file.exists(outfile)) file.remove(outfile)
d <- mapply(function(x, n) {
write.table(paste(c(x, n), collapse = "\t"),
file = outfile,
row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE)
}, names(dup_resp_comps),  dup_resp_comps)
# Write out sorted list of duplicated response components by signature
outfile = logfile_path(logdir, base_filename, "response_component_duplicates_sorted.txt")
if(file.exists(outfile)) file.remove(outfile)
d <- mapply(function(x, n) {
write.table(paste(c(x, sort(n)), collapse = "\t"),
file = outfile,
row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE)
}, names(dup_resp_comps), dup_resp_comps)
}
start_cnt <- nrow(df2)
# Update original gene symbols to latest versions (NCBI/HGNC)
if (sheet_type == "GENE") {
# starts with "genes" manually corrected list from above
# make sure "genes" is still in synch with df2.
length(genes) == nrow(df2)
rvl <- update_gene_symbols(genes, logdir, base_filename,
source_data_dir,
DOWNLOAD_NEW_HGNC)
genes_map <- rvl$genes_map
summary_df <- rbind(summary_df, rvl$summary)
rm(rvl)
# w <- which(genes_map$Symbol != genes_map$alias)
# Save the gene map for the unmatched symbols with their uniq_obs_id
# to add them back to complete signatures later
unmatched_symbols_map <- cbind(genes_map, uniq_obs_id = df2$uniq_obs_id)
unmatched_symbols_map <- unmatched_symbols_map[is.na(unmatched_symbols_map$Symbol), ]
# copy the fixed symbols back to the main data structure df2
df2$response_component <- genes_map$Symbol
# get rid of genes that had no valid symbol.
df2 <- df2[!is.na(df2$response_component), ]
# Remove genes that are OK in HGNC but fail at NCBI
if(exists("ncbi_no_symbol")) {
df2 <- df2[!(df2$response_component %in% ncbi_no_symbol), ]
}
# Fix symbols where NCBI is not using current HGNC symbol
if(exists("ncbi_fixes")) {
for(i in 1:nrow(ncbi_fixes)) {
df2$response_component[df2$response_component == ncbi_fixes$hgnc[i]] <- ncbi_fixes$ncbi[i]
}
}
summary_df <- add_to_summary(summary_df,
"Number of valid gene symbols" ,
length(unique(df2$response_component)))
} else if (sheet_type == "CELLTYPE_FREQUENCY") {
# ctf_match will have NA values where no match found
ctf_match <- match(df2$response_component_original, ctf_fixes$original_annotation)
# Test if any rows in cell-type mapping sheet are unused.
w <- !(1:length(ctf_fixes$original_annotation) %in% unique(ctf_match))
if(any(w)) {
print("not all cell-type mappings used:")
print(sapply(ctf_fixes$original_annotation[w], function(x) {which(ctf_fixes$original_annotation == x) + 1}))
} else {
print("all cell-type mappings used")
}
if (any(is.na(ctf_match))) {
w <- which(is.na(ctf_match))
print(paste("row", df2$uniq_obs_id[w], ", no mapping for cell type",
df2$response_component_original[w]))
missing_mappings <- data.frame(row = df2$uniq_obs_id[w], label = df2$response_component_original[w])
write.xlsx(missing_mappings,
file = logfile_path(logdir, base_filename, "missing_mappings.xlsx"),
sheetName = "all rows", append = FALSE, row.names = FALSE)
write.xlsx(unique(sort(df2$response_component_original[w])),
file = logfile_path(logdir, base_filename, "missing_mappings.xlsx"),
sheetName = "unique", append = TRUE, row.names = FALSE)
stop("cell type mapping not found")
} else {
print("all cell types matched")
}
failed_matches <- df2$response_component_original[is.na(ctf_match)]
successful_matches <- df2$response_component_original[!is.na(ctf_match)]
summary_df <- add_to_summary(summary_df, "Unique failed cell type tag matches",
length(unique(failed_matches)))
summary_df <- add_to_summary(summary_df, "Unique successful cell type tag matches" ,
length(unique(successful_matches)))
if (length(failed_matches) > 0) {
write.table(unique(failed_matches),
file = logfile_path(logdir, base_filename, "no_cell_type_match.txt"),
sep = "\t", row.names = FALSE, col.names = FALSE, quote = FALSE)
write.xlsx(unique(failed_matches),
file = logfile_path(logdir, base_filename, "no_cell_type_match.xlsx"),
row.names = FALSE, col.names = FALSE)
write.table(sort(failed_matches_uniq),
file = logfile_path(logdir, base_filename, "no_cell_type_match_sorted.txt"),
sep = "\t", row.names = FALSE, col.names = FALSE, quote = FALSE)
write.xlsx(sort(failed_matches_uniq),
file = logfile_path(logdir, base_filename, "no_cell_type_match_sorted.xlsx"),
row.names = FALSE, col.names = FALSE)
}
# combine proterm(s) and extra together.  All same length as df2.
proterm <- ctf_fixes$PRO_term_w_intensity[ctf_match]
extra <- ctf_fixes$extra[ctf_match]
# vector initialized with ""
proterm_and_extra <- vector(mode = "character", length = length(proterm))
for (i in 1:length(proterm)) {
if(is.na(ctf_match[i])) {
# should not happen, already checked
print(paste("no mapping for cell type at index", i))
next
}
# insert comma between non-empty terms
a <- c(proterm[i], extra[i])
a <- a[a!=""]                   # returns char(0) if both empty
a <- paste(a, collapse = ", ")  # returns "" on empty
proterm_and_extra[i] <- ifelse(a != "", paste("&", a), "")
}
df2$response_component <- ctf_fixes$CL_term[ctf_match]
df2$cell_ontology_id   <- ctf_fixes$CL_ID[ctf_match]
df2$proterm_and_extra  <- proterm_and_extra
df2$pro_ontology_id    <- ctf_fixes$PRO_ID[ctf_match]
df2$fully_qualified_response_component <- ""
# Remove any unmatched cell types (should have already been caught)
df2 <- df2[!is.na(ctf_match), ]
summary_df <- add_to_summary(summary_df,
"Unique cell types after substitutions",
length(unique(df2$response_component)))
# remove trailing white space if proterm_and_extra was empty
concatenated_cell_types <- trimws(paste(df2$response_component, df2$proterm_and_extra, sep = " "))
df2$fully_qualified_response_component <- concatenated_cell_types
concatenated_cell_types <- sort(unique(concatenated_cell_types))
write.table(concatenated_cell_types,
file = logfile_path(logdir, base_filename, "concatenated_cell_types.txt"),
sep = "\t", row.names = FALSE, col.names = FALSE, quote = FALSE)
summary_df <- add_to_summary(summary_df,
"Unique cell type + marker combinations",
length(concatenated_cell_types))
}
end_cnt <- nrow(df2)
summary_df <- add_to_summary(summary_df,
"Split 1, first reduction, rows lost to unknown response component",
start_cnt - end_cnt)
# Remove exact duplicates (implies duplicate copies of response component in a signature)
# This can happen when e.g. two or more original probesets get map to one symbol.
start_cnt <- end_cnt
df2 <- unique(df2)
end_cnt <- nrow(df2)
summary_df <- add_to_summary(summary_df, "Split 1, rows before removal" , start_cnt)
summary_df <- add_to_summary(summary_df, "Split 1, rows with non-unique response component removed" , start_cnt - end_cnt)
summary_df <- add_to_summary(summary_df, "Split 1, rows remaining", end_cnt)
start_cnt <- end_cnt
# get count of rows for each uniq_obs_id.
uids_list <- unique(df2$uniq_obs_id)
uids_cnt  <- sapply(uids_list, function(x) {sum(df2$uniq_obs_id == x)})
for (i in 1:length(uids_list)) {
df2$response_comp_cnt[df2$uniq_obs_id == uids_list[i]] <- uids_cnt[i]
}
start_cnt <- end_cnt
write_unique_list(df2$response_component, logdir, base_filename, "response_component_list")
#################################################
##### Data splitting (2): exposure material #####
#################################################
# Only gene and cell type frequency have data of this type so far
if (sheet_type == "CELLTYPE_FREQUENCY" | sheet_type == "GENE") {
write_unique_list(df2$exposure_material, logdir, base_filename, "exposure_material", do_split = TRUE)
df2 <- cSplit(df2, "exposure_material_id", sep = ";", direction = "long")
write_unique_list(df2$exposure_material_id, logdir, base_filename, "exposure_material_id", do_split = FALSE)
}
end_cnt <- nrow(df2)
summary_df <- add_to_summary(summary_df, "Split 2, on exposure material, rows added", end_cnt - start_cnt)
summary_df <- add_to_summary(summary_df, "Split 2, on exposure material, total rows", end_cnt)
summary_df <- add_to_summary(summary_df, "unique VO codes in exposure_material_id", length(unique(df2$exposure_material_id)))
start_cnt <- end_cnt
# The cSplit() calls produce a data.table of data.frame rows.  Coerce back to just data.frame.
df2 <- as.data.frame(df2, stringsAsFactors = FALSE)
# Substitute in actual virus components for influenza pathogens only.
for (i in 1:nrow(df2)) {
if(df2[i, "vaccine_year"] != "" ) {
df2[i, "target_pathogen"] <- lookup_vaccine(as.character(df2[i, "vaccine_year"]))
}
}
# Substitute in actual pathogens for measles + DPT vaccination
# Note - the specific pathogen strains below are not specified by the VO codes used.
# These are the only case in Gene and Cell-type where there are more than a single pathogen,
# other than for influenza, so have to rewrite the pathogen entries to match split vaccine VO codes
w <- which(df2$exposure_material_id == "VO_0000654")
df2[w, "target_pathogen"] <- "Measles virus strain Edmonston-Zagreb"
w <- which(df2$exposure_material_id == "VO_0000738")
df2[w, "target_pathogen"] <- "Corynebacterium diphtheriae; Clostridium tetani; Human poliovirus 1; Human poliovirus 2; Human poliovirus 3"
is.factor(df2$exposure_material_id)
#########################################
##### Data splitting (3): Pathogens #####
#########################################
# split
df2 <- cSplit(df2, "target_pathogen", sep = ";", direction = "long")
# class(df2)  # "data.table" "data.frame"
df2 <- as.data.frame(df2)
end_cnt <- nrow(df2)
summary_df <- add_to_summary(summary_df, "Split 3, on pathogens, rows added", end_cnt - start_cnt)
summary_df <- add_to_summary(summary_df, "Split 3, on pathogens, total rows", end_cnt)
start_cnt <- end_cnt
# Write unique list of pathogens after substitutions
write_unique_list(df2$target_pathogen, logdir, base_filename, "target_pathogens_after_fixes")
summary_df <- add_to_summary(summary_df, "target_pathogens_after_fixes", length(unique(df2$target_pathogen)))
# Now substitute for viral strains missing in NCBI Taxonomy
df2$target_pathogen <- sub("Influenza A virus \\(A/Switzerland/9715293/2013\\(H3N2\\)\\)", "H3N2 subtype", df2$target_pathogen)
df2$target_pathogen <- sub("Influenza B virus \\(B/Phuket/3073/2013\\)", "Influenza B virus", df2$target_pathogen)
# lowercase first letter of each pathogen
substr(df2$target_pathogen, 1, 1) <- tolower(substr(df2$target_pathogen, 1,1))
# Write unique list of pathogens after final substitutions
write_unique_list(df2$target_pathogen, logdir, base_filename, "target_pathogens_after_final_fixes")
summary_df <- add_to_summary(summary_df, "target_pathogens_after_final_fixes", length(unique(df2$target_pathogen)))
# Write unique list of tissue types
write_unique_list(df2$tissue_type, logdir, base_filename, "tissue_type_list")
summary_df <- add_to_summary(summary_df, "tissue types", length(unique(df2$tissue_type)))
####################################################################
#### Get counts of each response component for e.g. word cloud #####
####################################################################
response_df <- unique(df2[ , c("response_component", "uniq_obs_id")])
response_df <- as.data.frame(table(response_df$response_component))
colnames(response_df) <- c("response_component", "count")
response_df <- response_df[order(response_df$count, decreasing = TRUE), ]
#Write out counts in tab-delimited format
write.table(response_df,
file = logfile_path(logdir, base_filename, "response_component_counts.txt"),
sep = "\t", row.names = FALSE)
# Write out counts in Excel format
write.xlsx(response_df,
file = logfile_path(logdir, base_filename, "response_component_counts.xlsx"),
sheetName = sheet_name, row.names = FALSE)
# Write out counts in RDS format
saveRDS(response_df,
file = logfile_path(logdir, base_filename, "response_component_counts.RDS"))
##########################################################
####  Collect publication titles, dates and abstracts ####
##########################################################
pmids <- unique(df2$publication_reference_id)
summary_df <- add_to_summary(summary_df, "Unique PMIDs", length(pmids))
print_pub_year <- df2$publication_year[match(pmids, df2$publication_reference_id)]
# pmids <- 16571413   # for testing
# pmids <- "24336226" # for testing
# pmids <- "23594957" # for testing
if (RENEW_PMIDS || !file.exists(pmid_file)) {
td <- mapply(pmid_to_title_easy, pmids, print_pub_year, SIMPLIFY = FALSE)
titles_and_dates_df <- as.data.frame(rbindlist(td))
save(titles_and_dates_df, file = pmid_file)
} else {
load(file = pmid_file)
}
#############################################################
#### Recreate original spreadsheet with all corrections #####
#############################################################
# Collect multi-valued columns by unique observation ID (each row in original spreadsheet)
uniqIDs                    <- unique(df2$uniq_obs_id)
resp_components_cnt_df     <- data.frame()
resp_components_annotated  <- vector("list", length(uniqIDs))
resp_components_collected  <- vector("list", length(uniqIDs))
resp_components_full_sig   <- vector("list", length(uniqIDs))   # used for cell types only
recreated_template         <- vector("list", length(uniqIDs))
# Some signatures are lost entirely during cleaning
which(!(names(signatures_uniq) %in% uniqIDs))
signatures_uniq <- signatures_uniq[names(signatures_uniq) %in% uniqIDs]
# create data structures needed for mSigDB
if (sheet_type == "GENE" && CREATE_MSIGDB) {
msigdb_empty <- msigdb_intialize()
msigdb_list <- vector("list", length(uniqIDs))
}
for (i in 1:length(uniqIDs)) {
df2tmp <- df2[df2$uniq_obs_id == uniqIDs[i], ]
# Recreate a full signature in one row
base_row <- df2tmp[1, ] # get first row for this uniqID
response_rowname     <- paste(base_row$publication_reference_id, base_row$subm_obs_id, uniqIDs[i], sep = "_")
response_description <- paste("PMID", base_row$publication_reference_id, "submission", base_row$subm_obs_id, "row", uniqIDs[i], sep = " ")
# Use the full original set of response components rather than just those
# for which a valid symbol was found.
base_row$response_component_original <- paste(unique(df2tmp$response_component_original), collapse = "; ")
# The "updated" (gene or cell types after fixes) response_components
resp_components_collected[[i]] <- unique(df2tmp$response_component)  # genes or base cell types
if (sheet_type == "GENE") {
base_row$response_component <- paste(unique(df2tmp$response_component), collapse = "; ")
resp_components_annotated[[i]] <- c(response_rowname, response_description, unique(df2tmp$response_component))
# get abstract by PMID
w <- which(titles_and_dates_df$pmid == base_row$publication_reference_id)
if (length(w) != 1) {
stop(paste("unexpected PMID result: uniqID = ", uniqIDs[i], ", pmid = ", base_row$publication_reference_id))
}
titles_and_dates_row <- titles_and_dates_df[w, ]
if(CREATE_MSIGDB) {
# Create mSigDB submission row
msigdb_df <- msigdb_process_row(msigdb_empty, df2tmp)
msigdb_list[[i]] <- msigdb_df
}
} else if (sheet_type == "CELLTYPE_FREQUENCY") {
full_sig <- unique(df2tmp$fully_qualified_response_component)
base_row$response_component    <- paste(full_sig, collapse = "; ")
resp_components_full_sig[[i]]  <- full_sig
resp_components_annotated[[i]] <- c(response_rowname, response_description, full_sig)
}
tmp <- data.frame(rowname = response_rowname,
pmid = base_row$publication_reference_id,
subm_obs_id = base_row$subm_obs_id,
uniq_obs_id = uniqIDs[i],
count = length(resp_components_collected[[i]]))
resp_components_cnt_df <- rbind(resp_components_cnt_df, tmp)
# Reconstitute target_pathogen and exposure_material_id
base_row$target_pathogen   <- paste(unique(df2tmp$target_pathogen), collapse = "; ")
base_row$exposure_material_id <- paste(unique(df2tmp$exposure_material_id), collapse = "; ")
recreated_template[[i]] <- base_row
}
names(resp_components_collected) <- uniqIDs  # name not actually used again?
names(resp_components_full_sig)  <- uniqIDs  # name not actually used again?
names(resp_components_annotated) <- uniqIDs  # name is used for this one.
recreated_template_df <- as.data.frame(rbindlist(recreated_template))  # consolidate to a single data.frame
if(any(colnames(header_rows) != colnames(recreated_template_df))) {
stop("mismatch between header rows and recreated_template_df rows")
}
recreated_template_df <- rbind(header_rows, recreated_template_df)
# Finish up and write out mSigDB submission
if (sheet_type == "GENE" && CREATE_MSIGDB) {
summary_df <- write_msigdb_submission(msigdb_list, summary_df)
}
# Delete unneeded columns from the recreated template
if (sheet_type == "GENE") {
# do nothing
} else if (sheet_type == "CELLTYPE_FREQUENCY") {
del_cols <- c("proterm_and_extra", "fully_qualified_response_component")
recreated_template_df <- recreated_template_df[!colnames(recreated_template_df) %in% del_cols]
}
del_cols <- c("submission_name", "submission_date", "template_name", "short_comment", "process_note")
recreated_template_df <- recreated_template_df[!colnames(recreated_template_df) %in% del_cols]
# Set that first column name back to blank
colnames(recreated_template_df)[1] <- ""
# Write out the recreated upload template in tab-delimited format
write.table(recreated_template_df,
file = logfile_path(logdir, base_filename, "recreated_template.txt"),
sep = "\t", row.names = FALSE)
# Write out the recreated upload template in Excel format
write.xlsx(recreated_template_df,
file = logfile_path(logdir, base_filename, "recreated_template.xlsx"),
sheetName = sheet_name, row.names = FALSE)
# Write out the recreated upload template in RDS format
saveRDS(recreated_template_df,
file = logfile_path(logdir, base_filename, "recreated_template.RDS"))
########################################
##### Prepare submission templates #####
########################################
# Format URLs and handle case of multiple URLs
# Due to length restriction of 255 characters on evidence columns,
# can in practice only return at most two concatenated URLs.
# NOTE - There are special cases in this routine
# NOTE - Update code if new publication URL formats are added
df2$signature_source_url <- format_hipc_urls(df2$signature_source_url)
# do a final check for illegal characters in df2
s <- strict_char_check(df2, "\xa0")  # character 160.  Dashboard loader does not like it.
if(!is.null(s)) {
print(paste("for df2, found problems in column (row numbers do not include any header)", s))
}
s <- strict_char_check(df2, "\n")    # embedded newlines
if(!is.null(s)) {
print(paste("for df2, found problems in column (row numbers do not include any header)", s))
}
# Remove columns not needed for Dashboard.
del_cols <- c("exposure_material", "short_comment", "process_note")
df2 <- df2[!colnames(df2) %in% del_cols]
header_rows <- header_rows[!colnames(header_rows) %in% del_cols]
if (sheet_type == "GENE") {
write_submission_template(df2, header_rows, template_name, titles_and_dates_df,
resp_components_collected, unmatched_symbols_map,
sheet_type, project)
} else if (sheet_type == "CELLTYPE_FREQUENCY") {
write_submission_template(df2, header_rows, template_name, titles_and_dates_df,
resp_components_full_sig, unmatched_symbols_map = NULL,
sheet_type, project)
}
###########################################
##### Write out various summary files #####
###########################################
summary_df <- add_to_summary(summary_df, "total signatures", length(resp_components_collected))
dd0 <- sum(duplicated(resp_components_collected))
summary_df <- add_to_summary(summary_df, "duplicate signatures (response components only)", dd0)
dd0 <- length(unique(resp_components_collected))
summary_df <- add_to_summary(summary_df, "unique signatures (response components only)", dd0)
if (sheet_type == "GENE") {
# do nothing
} else if (sheet_type == "CELLTYPE_FREQUENCY") {
dd0 <- length(resp_components_full_sig)
summary_df <- add_to_summary(summary_df, "signatures (including proterms)", dd0)
dd0 <- length(unique(resp_components_full_sig))
summary_df <- add_to_summary(summary_df, "unique signatures (including proterms)", dd0)
outfile = logfile_path(logdir, base_filename, "full_signatures_with_proterms.txt")
if(file.exists(outfile)) file.remove(outfile)
d <- lapply(resp_components_full_sig,
function(x) {write.table(paste(x, collapse = "\t"),
file = outfile, row.names = FALSE, col.names = FALSE,
quote = FALSE, append = TRUE)})
outfile = logfile_path(logdir, base_filename, "full_signatures_with_proterms_unique.txt")
if(file.exists(outfile)) file.remove(outfile)
d <- lapply(unique(resp_components_full_sig),
function(x) {write.table(paste(x, collapse = "\t"),
file = outfile, row.names = FALSE, col.names = FALSE,
quote = FALSE, append = TRUE)})
}
write.csv(resp_components_cnt_df,
file = logfile_path(logdir, base_filename, "response_component_counts_by_row.csv"),
row.names = FALSE)
outfile = logfile_path(logdir, base_filename, "response_components.gmt.txt")
if(file.exists(outfile)) file.remove(outfile)
d <- lapply(resp_components_annotated,
function(x) write.table(paste(x, collapse = "\t"),
file = outfile, row.names = FALSE, col.names = FALSE,
quote = FALSE, append = TRUE))
# Convert to GMT format using same first two columns as resp_components_annotated.
# Using "c()" encloses each item or phrase in quotes.
# verify order unchanged
all(names(signatures_uniq) == names(resp_components_annotated))
signatures_uniq_gmt <- mapply(function(x, n) {
c(x[1], x[2], n)
}, resp_components_annotated, signatures_uniq)
outfile = logfile_path(logdir, base_filename, "response_components_original.gmt.txt")
if(file.exists(outfile)) file.remove(outfile)
d <- lapply(signatures_uniq_gmt,
function(x) write.table(paste(x, collapse = "\t"),
file = outfile, row.names = FALSE, col.names = FALSE,
quote = FALSE, append = TRUE))
# totals by PMID
rc_cnt_by_pmid <- lapply(pmids, function(pmid) {
vals <- resp_components_cnt_df[resp_components_cnt_df$pmid == pmid, "count"]
return(list(pmid = pmid, sum = sum(vals)))
})
rc_cnt_by_pmid <- rbindlist(rc_cnt_by_pmid)
# Note that response components can appear in more than one signature per PMID.  These are not unique counts.
write.csv(rc_cnt_by_pmid,
file = logfile_path(logdir, base_filename, "response_component_non-unique_count_by_PMID.csv"),
row.names = FALSE)
# Unique response component count by PMID
# ordered by count, but could as well be ordered by PMID
rc_cnt_by_pmid_uniq <- resp_comps_by_pmid(resp_components_annotated, pmids)
rc_cnt_by_pmid_uniq <- rc_cnt_by_pmid_uniq[order(rc_cnt_by_pmid_uniq$count, decreasing = TRUE), ]
write.csv(rc_cnt_by_pmid_uniq,
file = logfile_path(logdir, base_filename, "response_component_unique_count_by_PMID.csv"),
row.names = FALSE)
summary_df <- add_to_summary(summary_df, "min signature size", min(resp_components_cnt_df$count))
summary_df <- add_to_summary(summary_df, "max signature size", max(resp_components_cnt_df$count))
# uniq_obs_ids that got deleted because no valid response_component
s <- subset(uniq_obs_id_orig, !(uniq_obs_id_orig %in% uniqIDs))
s <- paste(s, collapse = " ")
summary_df <- add_to_summary(summary_df, "original template rows deleted", s)
write.csv(summary_df,
file = logfile_path(logdir, base_filename, "run_summary_counts.csv"),
row.names = FALSE)
# if have all available response types, write a joint summary
write_final_summary(all_response_types, logdir)
##########################
##### Generate Plots #####
##########################
# Plot a histogram of unique response components per PMID
# outfile <- paste(base_filename, "UniqueCountByPMID.png", sep = "-")
# png(outfile)
# if (sheet_type == "GENE") {
#   p <- ggplot(rc_cnt_by_pmid_uniq, aes(count)) + geom_histogram(bins = 10) + scale_x_log10()
#   p +  labs(x = "genes per PMID") + annotation_logticks(sides = "b")
# } else  if (sheet_type == "CELLTYPE_FREQUENCY") {
#   p <- ggplot(rc_cnt_by_pmid_uniq, aes(count)) + geom_histogram(bins = 10)
#   p +  labs(x = "Cell types per PMID")
# }
# dev.off()
# Plot a histogram of response_components per signature
png(logfile_path(logdir, base_filename, "unique_count_by_signature.png"))
if (sheet_type == "GENE") {
p2 <- ggplot(resp_components_cnt_df, aes(count)) + geom_histogram(bins = 10) + scale_x_log10()
p2 +  labs(x = "genes per signature") + annotation_logticks(sides = "b") + theme(axis.title.x = element_text(size = 14), axis.title.y = element_text(size = 14))
} else  if (sheet_type == "CELLTYPE_FREQUENCY") {
p2 <- ggplot(resp_components_cnt_df, aes(count)) + geom_histogram(bins = 9) + scale_x_continuous(breaks = seq(1, 9, 1))
p2 +  labs(x = "Cell types per signature") + theme(axis.title.x = element_text(size = 14), axis.title.y = element_text(size = 14))
}
dev.off()
#################################
##### Write out sessionInfo #####
#################################
writeLines(capture.output(sessionInfo()),
logfile_path(logdir, base_filename, "session_info.txt"))
load(file = "//isilon.c2b2.columbia.edu/ifs/archive/shares/af_lab/CPTAC/ARACNe/ All_62_ARACNE.rda")
load(file = "W:/CPTAC/ARACNe/ All_62_ARACNE.rda")
load(file = "W:/CPTAC/ARACNe/All_62_ARACNE.rda")
load("W:/GTEx/RDA_Files/All_62_ARACNE.rda")
README
README()
View(tfPairEnrich)
a <- tfPairEnrich[[2]][400]
a
head(a)
dim(a)
lenght(a)
length(a)
class(a)
a[1]
a[[1]]
colnames(a)
head(a, 10)
View(tfPairEnrich)
View(tfPairEnrich)
tfPairEnrich[[1]]
a
tfPairEnrich[[1]][400]
View(tfPairEnrich)
view(tfPairEnrich[[1]])
View(tfPairEnrich[[1]])
tfPairEnrich[[1]][1,4]
tfPairEnrich[[1]][1,7]
head(tfPairEnrich[[2]][[1]])
head(tfPairEnrich[[2]][[400]])
README()
